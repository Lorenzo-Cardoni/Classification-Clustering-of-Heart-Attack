Il passo successivo è quello di dividere i dati in Training set e Test set e per farlo utilizziamo
la funzione train_test_split() al cui interno viene impostata la test_size ovvero la frazione
di dataset che si vuole dare al Test set e in questo caso abbiamo impostato 0.2 quindi avremo
una divisione Training set-80% e Test set-20%.

Per la scelta dei modelli di classificazione, abbiamo deciso di utilizzarne 7 per vederne le
differenze e quale si adattava meglio ai nostri dati, per questo utilizzeremo:

Classificatori dal implementare:

1) DecisionTreeClassifier  (FATTO STANDARD E GRID SEARCH)
2) LogisticRegression  (FATTO STANDARD E GRID SEARCH)
3) SVC (SUpport Vector Classifier) (FATTO STANDARD E GRID SEARCH)
4) RandomForestClassifier (FATTO STANDARD E GRID SEARCH)
5) AdaBoostClassifer (FATTO STANDARD E GRID SEARCH)
6) GradientBoostingClassifier (FATTO STANDARD E GRID SEARCH)
7) XGBoost (FATTO STANDARD E GRID SEARCH)
8) LinearDiscriminantAnalysis (FATTO STANDARD E GRID SEARCH)

Per trovare la migliore combinazione di iperparametri si è utilizzata la Grid Search.
